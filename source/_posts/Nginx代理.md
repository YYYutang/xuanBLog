---
title: 为什么要用nginx代理？
categories: 项目
tags: [项目,前端]
cover: /picture/qianduan.jpg
date: 2024-03-30 22:45
---

面试的时候，面试官问了我一个问题：为什么你们的项目需要用nginx部署呢？

说实话，这个问题在此前我并没有认真思考过，只是看到网络上说部署项目大家都用nginx，就按着流程按部就班地做了。今天整理了一下nginx的特点，并且就此分析了为什么我们的项目组选用了nginx部署。

## nginx的优势

- 高性能：Nginx采用事件驱动模型和异步非阻塞IO处理，能够处理大量并发连接，具有出色的性能表现。
- 轻量级：Nginx的设计目标是高性能和低资源消耗，具有小巧、简单的特点。
- 可扩展性：Nginx可以通过添加模块来扩展其功能，满足不同场景的需求。
- 高可靠性：Nginx具有优秀的稳定性和健壮性，能够处理高负载和峰值流量。
- 配置简单：Nginx的配置文件采用简洁的语法，易于理解和维护。

## nginx的作用

Nginx 的最重要的几个使用场景：

1. 静态资源服务，通过本地文件系统提供服务；
2. 反向代理服务，延伸出包括缓存、负载均衡等；
3. `API` 服务， `OpenResty` ；

下面分别对这些场景做一个介绍。首先我们需要了解正向代理与反向代理的概念。

### 正向代理

> 正向代理，意思是一个位于客户端和原始服务器(origin server)之间的服务器，为了从原始服务器取得内容，客户端向代理发送一个请求并指定目标(原始服务器)，然后代理向原始服务器转交请求并将获得的内容返回给客户端。

正向代理是为我们服务的，即为客户端服务的，客户端可以根据正向代理访问到它本身无法访问到的服务器资源。 

正向代理对我们是透明的，对服务端是非透明的，即服务端并不知道自己收到的是来自代理的访问还是来自真实客户端的访问。 

### 反向代理

- 反向代理 \*（Reverse Proxy）方式是指以代理服务器来接受internet上的连接请求，然后将请求转发给内部网络上的服务器，并将从服务器上得到的结果返回给internet上请求连接的客户端，此时代理服务器对外就表现为一个反向代理服务器。

反向代理是为服务端服务的，反向代理可以帮助服务器接收来自客户端的请求，帮助服务器做请求转发，负载均衡等。

反向代理对服务端是透明的，对我们是非透明的，即我们并不知道自己访问的是代理服务器，而服务器知道反向代理在为他服务。

反向代理的优势：

- 隐藏真实服务器；
- 负载均衡便于横向扩充后端动态服务；
- 动静分离，提升系统健壮性；

那么“动静分离”是什么？负载均衡又是什么？

### 动静分离

动静分离是指在 `web` 服务器架构中，将静态页面与动态页面或者静态内容接口和动态内容接口分开不同系统访问的架构设计方法，进而提示整个服务的访问性和可维护性。

![](1.png)

一般来说，都需要将动态资源和静态资源分开，由于 `Nginx` 的高并发和静态资源缓存等特性，经常将静态资源部署在 `Nginx` 上。如果请求的是静态资源，直接到静态资源目录获取资源，如果是动态资源的请求，则利用反向代理的原理，把请求转发给对应后台应用去处理，从而实现动静分离。

使用前后端分离后，可以很大程度提升静态资源的访问速度，即使动态服务不可用，静态资源的访问也不会受到影响。 

### 负载均衡

一般情况下，客户端发送多个请求到服务器，服务器处理请求，其中一部分可能要操作一些资源比如数据库、静态资源等，服务器处理完毕后，再将结果返回给客户端。 

这种模式对于早期的系统来说，功能要求不复杂，且并发请求相对较少的情况下还能胜任，成本也低。随着信息数量不断增长，访问量和数据量飞速增长，以及系统业务复杂度持续增加，这种做法已无法满足要求，并发量特别大时，服务器容易崩。 

很明显这是由于服务器性能的瓶颈造成的问题，除了堆机器之外，最重要的做法就是负载均衡。

请求爆发式增长的情况下，单个机器性能再强劲也无法满足要求了，这个时候集群的概念产生了，单个服务器解决不了的问题，可以使用多个服务器，然后将请求分发到各个服务器上，将负载分发到不同的服务器，这就是负载均衡，核心是「分摊压力」。 `Nginx` 实现负载均衡，一般来说指的是将请求转发给服务器集群。

举个具体的例子，晚高峰乘坐地铁的时候，入站口经常会有地铁工作人员大喇叭“请走 `B` 口， `B` 口人少车空....”，这个工作人员的作用就是负载均衡。

![](2.png)

`Nginx` 实现负载均衡的策略：

- 轮询策略：默认情况下采用的策略，将所有客户端请求轮询分配给服务端。这种策略是可以正常工作的，但是如果其中某一台服务器压力太大，出现延迟，会影响所有分配在这台服务器下的用户。
- 最小连接数策略：将请求优先分配给压力较小的服务器，它可以平衡每个队列的长度，并避免向压力大的服务器添加更多的请求。
- 最快响应时间策略：优先分配给响应时间最短的服务器。
- 客户端 `ip` 绑定策略：来自同一个 `ip` 的请求永远只分配一台服务器，有效解决了动态网页存在的 `session` 共享问题。

那么结合上面说的这些点，项目部署为什么要用到nginx的答案也就呼之欲出了。无非就包括以下几点：

1. 轻松支持 https
2. 解决前后端跨域问题
3. 前后端解耦，方便维护以及负载均衡
4. Nginx静态资源处理性能要比后端常用的容器高数倍
5. Nginx接收外部访问，类似于后端服务的防火墙，更安全

另外，我们的项目由于有多个服务，利用nginx可以统一入口。这样，用户访问时只需要知道一个域名和标准端口（如80或443），Nginx根据请求的URL路径或其他条件将请求转发到对应的内部端口。这样的配置简化了外部访问路径，对用户来说更加方便。
